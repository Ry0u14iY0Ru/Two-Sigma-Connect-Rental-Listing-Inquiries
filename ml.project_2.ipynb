{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer the questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derive an analytical solution to the regression problem. Use a vector form of the equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a basic linear regression model, we want to find the best-fitting line for a dataset of input features X and an output target y. The relationship can be modeled as:            \n",
    "y = Xβ + ϵ, where:\n",
    "\n",
    "1. y is the vector of observed values,\n",
    "2. is the matrix of input features (with an additional column of ones for the intercept),\n",
    "3. β is the vector of coefficients (weights), and\n",
    "4. ϵ is the error term.   \n",
    "    \n",
    "The goal is to minimize the sum of squared errors (SSE) given by:   \n",
    "L(β)=∣∣y−Xβ∣∣^2   \n",
    "To derive the analytical solution, we set the gradient of the loss function with respect to β to zero:   \n",
    "∇L(β) = −2X^T * (y−Xβ) = 0   \n",
    "This leads to the normal equation:   \n",
    "X^T * Xβ = X^T * y   \n",
    "Assuming X^T * x is invertible, the analytical solution for β is:   \n",
    "β=(X^T * X) ^ -1 * X^T * y    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What changes in the solution when L1 and L2 regularizations are added to the loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we add regularizations:\n",
    "1. L2 Regularization (Ridge Regression): The loss function modifies to:   \n",
    "L(β)=∣∣y−Xβ∣∣^2 + λ∣∣β∣∣^2   \n",
    "The solution for β becomes: β=(X^T * X+λI)^−1 * X^T * y   \n",
    "Here, λ is the regularization parameter that controls the strength of the penalty. L2 regularization shrinks the coefficients but does not set them to zero.   \n",
    "2. L1 Regularization (Lasso Regression): The loss function modifies to:   \n",
    "L(β)=∣∣y−Xβ∣∣^2 + λ∣∣β∣∣  \n",
    "The presence of the L1 penalty leads to a non-differentiable term, which causes some coefficients to become exactly zero, effectively selecting a simpler model by performing feature selection.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain why L1 regularization is often used to select features. Why are there many weights equal to 0 after the model is fit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L1 regularization is often preferred for feature selection because:\n",
    "1. It induces sparsity in the coefficient vector β. As a result, many coefficients are pushed to zero, thus selecting only a subset of the features in the data.\n",
    "2. This property is beneficial for scenarios with high-dimensional data where many features might be irrelevant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After fitting a model with L1 regularization many weights become exactly zero, indicating that those features do not contribute significantly to the prediction of the target variable. Therefore, these features can be safely excluded from the model without much loss of information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain how you can use the same models (Linear regression, Ridge, etc.) but make it possible to fit nonlinear dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fit nonlinear dependencies while using models like Linear Regression, Ridge, etc., we can apply several techniques:\n",
    "1. Polynomial Features:   \n",
    "Transform input features into polynomial terms. For a feature x, we can add x^2, x^3, etc.   \n",
    "2. Feature Interactions:   \n",
    "Create new features by multiplying existing features, which allow the model to capture interaction effects.\n",
    "3. Splines and Basis Functions:   \n",
    "Use splines or radial basis functions to represent nonlinear relationships.\n",
    "4. Kernel Tricks:   \n",
    "For models like Support Vector Machines (SVM) or Gaussian Processes, using a kernel method implicitly maps the input into a higher-dimensional space where a linear separation could occur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>features</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[Dining Room, Pre-War, Laundry in Building, Di...</td>\n",
       "      <td>2400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>[Doorman, Elevator, Laundry in Building, Dishw...</td>\n",
       "      <td>3800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>[Doorman, Elevator, Laundry in Building, Laund...</td>\n",
       "      <td>3495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.5</td>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[Doorman, Elevator, Fitness Center, Laundry in...</td>\n",
       "      <td>2795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124000</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>[Elevator, Dishwasher, Hardwood Floors]</td>\n",
       "      <td>2800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124002</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>[Common Outdoor Space, Cats Allowed, Dogs Allo...</td>\n",
       "      <td>2395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124004</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[Dining Room, Elevator, Pre-War, Laundry in Bu...</td>\n",
       "      <td>1850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124008</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>[Pre-War, Laundry in Unit, Dishwasher, No Fee,...</td>\n",
       "      <td>4195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124009</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>[Dining Room, Elevator, Laundry in Building, D...</td>\n",
       "      <td>4280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48379 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        bathrooms  bedrooms  \\\n",
       "4             1.0         1   \n",
       "6             1.0         2   \n",
       "9             1.0         2   \n",
       "10            1.5         3   \n",
       "15            1.0         0   \n",
       "...           ...       ...   \n",
       "124000        1.0         3   \n",
       "124002        1.0         2   \n",
       "124004        1.0         1   \n",
       "124008        1.0         2   \n",
       "124009        1.0         3   \n",
       "\n",
       "                                                 features  price  \n",
       "4       [Dining Room, Pre-War, Laundry in Building, Di...   2400  \n",
       "6       [Doorman, Elevator, Laundry in Building, Dishw...   3800  \n",
       "9       [Doorman, Elevator, Laundry in Building, Laund...   3495  \n",
       "10                                                     []   3000  \n",
       "15      [Doorman, Elevator, Fitness Center, Laundry in...   2795  \n",
       "...                                                   ...    ...  \n",
       "124000            [Elevator, Dishwasher, Hardwood Floors]   2800  \n",
       "124002  [Common Outdoor Space, Cats Allowed, Dogs Allo...   2395  \n",
       "124004  [Dining Room, Elevator, Pre-War, Laundry in Bu...   1850  \n",
       "124008  [Pre-War, Laundry in Unit, Dishwasher, No Fee,...   4195  \n",
       "124009  [Dining Room, Elevator, Laundry in Building, D...   4280  \n",
       "\n",
       "[48379 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_data = pd.read_json('data/train.json')\n",
    "data_trains = raw_train_data[['bathrooms', 'bedrooms', 'features', 'price']]\n",
    "data_train = data_trains.copy()\n",
    "\n",
    "lower_bound = data_train['price'].quantile(0.01)\n",
    "upper_bound = data_train['price'].quantile(0.99)\n",
    "data_train = data_train[(data_train['price'] >= lower_bound) & (data_train['price'] <= upper_bound)]\n",
    "\n",
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>features</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[Elevator, Laundry in Building, Laundry in Uni...</td>\n",
       "      <td>2950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>[Pre-War, Dogs Allowed, Cats Allowed]</td>\n",
       "      <td>2850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[Pre-War, Dogs Allowed, Cats Allowed]</td>\n",
       "      <td>2295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>[Hardwood Floors, Dogs Allowed, Cats Allowed]</td>\n",
       "      <td>2900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[Roof Deck, Doorman, Elevator, Fitness Center,...</td>\n",
       "      <td>3254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124003</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>1700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124005</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>[Doorman, Elevator, Laundry in Building, Dishw...</td>\n",
       "      <td>4195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124006</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[Dogs Allowed, Cats Allowed]</td>\n",
       "      <td>2400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124007</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>[Doorman, Elevator, Cats Allowed, Dogs Allowed]</td>\n",
       "      <td>6895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124010</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>[Garden/Patio, Laundry in Unit, Dishwasher, Ha...</td>\n",
       "      <td>4695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74659 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        bathrooms  bedrooms  \\\n",
       "0             1.0         1   \n",
       "1             1.0         2   \n",
       "2             1.0         0   \n",
       "3             1.0         2   \n",
       "5             1.0         1   \n",
       "...           ...       ...   \n",
       "124003        1.0         1   \n",
       "124005        1.0         2   \n",
       "124006        1.0         0   \n",
       "124007        2.0         2   \n",
       "124010        1.0         3   \n",
       "\n",
       "                                                 features  price  \n",
       "0       [Elevator, Laundry in Building, Laundry in Uni...   2950  \n",
       "1                   [Pre-War, Dogs Allowed, Cats Allowed]   2850  \n",
       "2                   [Pre-War, Dogs Allowed, Cats Allowed]   2295  \n",
       "3           [Hardwood Floors, Dogs Allowed, Cats Allowed]   2900  \n",
       "5       [Roof Deck, Doorman, Elevator, Fitness Center,...   3254  \n",
       "...                                                   ...    ...  \n",
       "124003                                                 []   1700  \n",
       "124005  [Doorman, Elevator, Laundry in Building, Dishw...   4195  \n",
       "124006                       [Dogs Allowed, Cats Allowed]   2400  \n",
       "124007    [Doorman, Elevator, Cats Allowed, Dogs Allowed]   6895  \n",
       "124010  [Garden/Patio, Laundry in Unit, Dishwasher, Ha...   4695  \n",
       "\n",
       "[74659 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_test_data = pd.read_json('data/test.json')\n",
    "data_tests = raw_test_data[['bathrooms', 'bedrooms', 'features', 'price']]\n",
    "data_test = data_tests.copy()\n",
    "\n",
    "data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro data analysis part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_features(features):\n",
    "    cleaned_features = []\n",
    "    for f in features:\n",
    "        # Remove extra characters\n",
    "        cleaned_f = str(f).replace(\"'\", \"\").replace('\"', '').replace('[', '').replace(']', '').strip()\n",
    "        cleaned_features.append(cleaned_f)\n",
    "    return cleaned_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество уникальных значений: 1536\n",
      "Топ-20 популярных функций: [('Elevator', 25398), ('Hardwood Floors', 23159), ('Cats Allowed', 23148), ('Dogs Allowed', 21662), ('Doorman', 20497), ('Dishwasher', 20095), ('No Fee', 17806), ('Laundry in Building', 16093), ('Fitness Center', 13000), ('Pre-War', 8978), ('Laundry in Unit', 8448), ('Roof Deck', 6423), ('Outdoor Space', 5137), ('Dining Room', 4901), ('High Speed Internet', 4225), ('Balcony', 2898), ('Swimming Pool', 2648), ('Laundry In Building', 2565), ('New Construction', 2507), ('Terrace', 2179)]\n",
      "Список всех признаков: ['bathrooms', 'bedrooms', 'Elevator', 'Hardwood Floors', 'Cats Allowed', 'Dogs Allowed', 'Doorman', 'Dishwasher', 'No Fee', 'Laundry in Building', 'Fitness Center', 'Pre-War', 'Laundry in Unit', 'Roof Deck', 'Outdoor Space', 'Dining Room', 'High Speed Internet', 'Balcony', 'Swimming Pool', 'Laundry In Building', 'New Construction', 'Terrace']\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48379 entries, 0 to 48378\n",
      "Data columns (total 23 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   bathrooms            48379 non-null  float64\n",
      " 1   bedrooms             48379 non-null  int64  \n",
      " 2   price                48379 non-null  int64  \n",
      " 3   Elevator             48379 non-null  int64  \n",
      " 4   Hardwood Floors      48379 non-null  int64  \n",
      " 5   Cats Allowed         48379 non-null  int64  \n",
      " 6   Dogs Allowed         48379 non-null  int64  \n",
      " 7   Doorman              48379 non-null  int64  \n",
      " 8   Dishwasher           48379 non-null  int64  \n",
      " 9   No Fee               48379 non-null  int64  \n",
      " 10  Laundry in Building  48379 non-null  int64  \n",
      " 11  Fitness Center       48379 non-null  int64  \n",
      " 12  Pre-War              48379 non-null  int64  \n",
      " 13  Laundry in Unit      48379 non-null  int64  \n",
      " 14  Roof Deck            48379 non-null  int64  \n",
      " 15  Outdoor Space        48379 non-null  int64  \n",
      " 16  Dining Room          48379 non-null  int64  \n",
      " 17  High Speed Internet  48379 non-null  int64  \n",
      " 18  Balcony              48379 non-null  int64  \n",
      " 19  Swimming Pool        48379 non-null  int64  \n",
      " 20  Laundry In Building  48379 non-null  int64  \n",
      " 21  New Construction     48379 non-null  int64  \n",
      " 22  Terrace              48379 non-null  int64  \n",
      "dtypes: float64(1), int64(22)\n",
      "memory usage: 8.5 MB\n"
     ]
    }
   ],
   "source": [
    "# Clearing the Features column\n",
    "data_train['features'] = data_train['features'].apply(clean_features)\n",
    "\n",
    "# Create a list of all functions\n",
    "all_features = []\n",
    "for index, row in data_train.iterrows():\n",
    "    # Separate the values ​​by commas and add them to the general list\n",
    "    features = row['features']\n",
    "    all_features.extend(features)\n",
    "\n",
    "# Counting unique values\n",
    "unique_values = set(all_features)\n",
    "print(f\"Количество уникальных значений: {len(unique_values)}\")\n",
    "\n",
    "# Using the collections library to count frequencies\n",
    "counter = Counter(all_features)\n",
    "top_20_features = counter.most_common(20)\n",
    "print(f\"Топ-20 популярных функций: {top_20_features}\")\n",
    "\n",
    "# Creating new features based on top 20 functions\n",
    "for feature_name, _ in top_20_features:\n",
    "    data_train[feature_name] = data_train['features'].apply(lambda x: int(feature_name in x))\n",
    "\n",
    "# Combining all features into one list\n",
    "feature_list = ['bathrooms', 'bedrooms'] + [x[0] for x in top_20_features]\n",
    "print(f\"Список всех признаков: {feature_list}\")\n",
    "\n",
    "data_train.drop(columns=['features'], inplace=True)\n",
    "data_train.reset_index(drop=True, inplace=True)\n",
    "data_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество уникальных значений: 2101\n",
      "Список всех признаков: ['bathrooms', 'bedrooms', 'Elevator', 'Hardwood Floors', 'Cats Allowed', 'Dogs Allowed', 'Doorman', 'Dishwasher', 'No Fee', 'Laundry in Building', 'Fitness Center', 'Pre-War', 'Laundry in Unit', 'Roof Deck', 'Outdoor Space', 'Dining Room', 'High Speed Internet', 'Balcony', 'Swimming Pool', 'Laundry In Building', 'New Construction', 'Terrace']\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 74659 entries, 0 to 74658\n",
      "Data columns (total 23 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   bathrooms            74659 non-null  float64\n",
      " 1   bedrooms             74659 non-null  int64  \n",
      " 2   price                74659 non-null  int64  \n",
      " 3   Elevator             74659 non-null  int64  \n",
      " 4   Hardwood Floors      74659 non-null  int64  \n",
      " 5   Cats Allowed         74659 non-null  int64  \n",
      " 6   Dogs Allowed         74659 non-null  int64  \n",
      " 7   Doorman              74659 non-null  int64  \n",
      " 8   Dishwasher           74659 non-null  int64  \n",
      " 9   No Fee               74659 non-null  int64  \n",
      " 10  Laundry in Building  74659 non-null  int64  \n",
      " 11  Fitness Center       74659 non-null  int64  \n",
      " 12  Pre-War              74659 non-null  int64  \n",
      " 13  Laundry in Unit      74659 non-null  int64  \n",
      " 14  Roof Deck            74659 non-null  int64  \n",
      " 15  Outdoor Space        74659 non-null  int64  \n",
      " 16  Dining Room          74659 non-null  int64  \n",
      " 17  High Speed Internet  74659 non-null  int64  \n",
      " 18  Balcony              74659 non-null  int64  \n",
      " 19  Swimming Pool        74659 non-null  int64  \n",
      " 20  Laundry In Building  74659 non-null  int64  \n",
      " 21  New Construction     74659 non-null  int64  \n",
      " 22  Terrace              74659 non-null  int64  \n",
      "dtypes: float64(1), int64(22)\n",
      "memory usage: 13.1 MB\n"
     ]
    }
   ],
   "source": [
    "# Clearing the Features column\n",
    "data_test['features'] = data_test['features'].apply(clean_features)\n",
    "\n",
    "# Create a list of all functions\n",
    "all_features = []\n",
    "for index, row in data_test.iterrows():\n",
    "    # Separate the values ​​by commas and add them to the general list\n",
    "    features = row['features']\n",
    "    all_features.extend(features)\n",
    "\n",
    "# Counting unique values\n",
    "unique_values = set(all_features)\n",
    "print(f\"Количество уникальных значений: {len(unique_values)}\")\n",
    "\n",
    "# Creating new features based on top 20 functions\n",
    "for feature_name, _ in top_20_features:\n",
    "    data_test[feature_name] = data_test['features'].apply(lambda x: int(feature_name in x))\n",
    "\n",
    "# Combining all features into one list\n",
    "feature_list = ['bathrooms', 'bedrooms'] + [x[0] for x in top_20_features]\n",
    "print(f\"Список всех признаков: {feature_list}\")\n",
    "\n",
    "data_test.drop(columns=['features'], inplace=True)\n",
    "data_test.reset_index(drop=True, inplace=True)\n",
    "data_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models implementation — Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My LinearRegressionSGN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_train.drop('price', axis=1)\n",
    "y_train = data_train['price']\n",
    "X_test = data_test.drop('price', axis=1)\n",
    "y_test = data_test['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=48379, step=1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionSGD:\n",
    "    def __init__(self, learning_rate=0.01, n_iterations=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iterations = n_iterations\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "        \n",
    "        for _ in range(self.n_iterations):\n",
    "            for idx in range(n_samples):\n",
    "                linear_pred = np.dot(X[idx], self.weights) + self.bias\n",
    "                error = linear_pred - y[idx]\n",
    "                \n",
    "                # Updating weights and bias\n",
    "                self.weights -= self.learning_rate * error * X[idx]\n",
    "                self.bias -= self.learning_rate * error\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.dot(X, self.weights) + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionAnalytic:\n",
    "    def fit(self, X, y):\n",
    "        X_b = np.c_[np.ones((X.shape[0], 1)), X]  # add x0 = 1\n",
    "        self.weights = np.linalg.inv(X_b.T @ X_b) @ X_b.T @ y\n",
    "\n",
    "    def predict(self, X):\n",
    "        X_b = np.c_[np.ones((X.shape[0], 1)), X]  # add x0 = 1\n",
    "        return X_b @ self.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_score(y_true, y_pred):\n",
    "    ss_total = np.sum((y_true - np.mean(y_true)) ** 2)\n",
    "    ss_residual = np.sum((y_true - y_pred) ** 2)\n",
    "    return 1 - (ss_residual / ss_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return mae, rmse, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_sgd = LinearRegressionSGD()\n",
    "linear_sgd.fit(X_train, y_train)\n",
    "y_train_pred_sgd = linear_sgd.predict(X_train)\n",
    "y_test_pred_sgd = linear_sgd.predict(X_test)\n",
    "\n",
    "linear_analytic = LinearRegressionAnalytic()\n",
    "linear_analytic.fit(X_train, y_train)\n",
    "y_train_pred_anal = linear_analytic.predict(X_train)\n",
    "y_test_pred_anal = linear_analytic.predict(X_test)\n",
    "\n",
    "sklearn_model = LinearRegression()\n",
    "sklearn_model.fit(X_train, y_train)\n",
    "y_train_pred_sklearn = sklearn_model.predict(X_train)\n",
    "y_test_pred_sklearn = sklearn_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train MAE</th>\n",
       "      <th>Test MAE</th>\n",
       "      <th>Train RMSE</th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>Train R2</th>\n",
       "      <th>Test R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegressionSGD</td>\n",
       "      <td>718.081663</td>\n",
       "      <td>920.993858</td>\n",
       "      <td>1071.763291</td>\n",
       "      <td>9609.922737</td>\n",
       "      <td>0.549975</td>\n",
       "      <td>0.021117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearRegressionAnalytic</td>\n",
       "      <td>711.791166</td>\n",
       "      <td>909.889672</td>\n",
       "      <td>1035.351576</td>\n",
       "      <td>9603.903231</td>\n",
       "      <td>0.580034</td>\n",
       "      <td>0.022343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LinearRegression / Sk</td>\n",
       "      <td>711.791166</td>\n",
       "      <td>909.889672</td>\n",
       "      <td>1035.351576</td>\n",
       "      <td>9603.903231</td>\n",
       "      <td>0.580034</td>\n",
       "      <td>0.022343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model   Train MAE    Test MAE   Train RMSE    Test RMSE  \\\n",
       "0       LinearRegressionSGD  718.081663  920.993858  1071.763291  9609.922737   \n",
       "1  LinearRegressionAnalytic  711.791166  909.889672  1035.351576  9603.903231   \n",
       "2     LinearRegression / Sk  711.791166  909.889672  1035.351576  9603.903231   \n",
       "\n",
       "   Train R2   Test R2  \n",
       "0  0.549975  0.021117  \n",
       "1  0.580034  0.022343  \n",
       "2  0.580034  0.022343  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = {\n",
    "    'Model': [],\n",
    "    'Train MAE': [],\n",
    "    'Test MAE': [],\n",
    "    'Train RMSE': [],\n",
    "    'Test RMSE': [],\n",
    "    'Train R2': [],\n",
    "    'Test R2': []\n",
    "}\n",
    "\n",
    "for name, y_train_pred, y_test_pred in [\n",
    "    ('LinearRegressionSGD', y_train_pred_sgd, y_test_pred_sgd),\n",
    "    ('LinearRegressionAnalytic', y_train_pred_anal, y_test_pred_anal),\n",
    "    ('LinearRegression / Sk', y_train_pred_sklearn, y_test_pred_sklearn),\n",
    "]:\n",
    "    train_mae, train_rmse, train_r2 = evaluate_model(y_train, y_train_pred)\n",
    "    test_mae, test_rmse, test_r2 = evaluate_model(y_test, y_test_pred)\n",
    "    \n",
    "    metrics['Model'].append(name)\n",
    "    metrics['Train MAE'].append(train_mae)\n",
    "    metrics['Test MAE'].append(test_mae)\n",
    "    metrics['Train RMSE'].append(train_rmse)\n",
    "    metrics['Test RMSE'].append(test_rmse)\n",
    "    metrics['Train R2'].append(train_r2)\n",
    "    metrics['Test R2'].append(test_r2)\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularized models implementation — Ridge, Lasso, ElasticNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My implementation of RidgeRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RidgeRegression:\n",
    "    def __init__(self, alpha=1.0, learning_rate=0.01, n_iterations=1000):\n",
    "        self.alpha = alpha\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iterations = n_iterations\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "        \n",
    "        for _ in range(self.n_iterations):\n",
    "            linear_pred = np.dot(X, self.weights) + self.bias\n",
    "            error = linear_pred - y\n",
    "            \n",
    "            # Update weights with L2 regularization\n",
    "            dw = (1/n_samples) * np.dot(X.T, error) + (self.alpha/n_samples) * self.weights\n",
    "            db = (1/n_samples) * np.sum(error)\n",
    "            \n",
    "            self.weights -= self.learning_rate * dw\n",
    "            self.bias -= self.learning_rate * db\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.dot(X, self.weights) + self.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My implementation of LassoRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LassoRegression:\n",
    "    def __init__(self, alpha=1.0, learning_rate=0.01, n_iterations=1000):\n",
    "        self.alpha = alpha\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iterations = n_iterations\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "        \n",
    "        for _ in range(self.n_iterations):\n",
    "            linear_pred = np.dot(X, self.weights) + self.bias\n",
    "            error = linear_pred - y\n",
    "            \n",
    "            # Update weights with L1 regularization\n",
    "            dw = (1/n_samples) * np.dot(X.T, error)\n",
    "            \n",
    "            # Applying L1 regularization (simplified subgradient approach)\n",
    "            dw += self.alpha * np.sign(self.weights)\n",
    "            db = (1/n_samples) * np.sum(error)\n",
    "            \n",
    "            self.weights -= self.learning_rate * dw\n",
    "            self.bias -= self.learning_rate * db\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.dot(X, self.weights) + self.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My implementation of ElasticNetRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElasticNetRegression:\n",
    "    def __init__(self, alpha=1.0, lambda_l1=0.5, learning_rate=0.01, n_iterations=1000):\n",
    "        self.alpha = alpha\n",
    "        self.lambda_l1 = lambda_l1\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iterations = n_iterations\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "        \n",
    "        for _ in range(self.n_iterations):\n",
    "            linear_pred = np.dot(X, self.weights) + self.bias\n",
    "            error = linear_pred - y\n",
    "            \n",
    "            # Update weights taking into account both regularizations\n",
    "            dw = (1/n_samples) * np.dot(X.T, error) + self.alpha * (1 - self.lambda_l1) * self.weights\n",
    "            dw += self.alpha * self.lambda_l1 * np.sign(self.weights)\n",
    "            db = (1/n_samples) * np.sum(error)\n",
    "            \n",
    "            self.weights -= self.learning_rate * dw\n",
    "            self.bias -= self.learning_rate * db\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.dot(X, self.weights) + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_model = RidgeRegression(alpha=1.0)\n",
    "ridge_model.fit(X_train, y_train)\n",
    "y_train_pred_ridge = ridge_model.predict(X_train)\n",
    "y_test_pred_ridge = ridge_model.predict(X_test)\n",
    "\n",
    "lasso_model = LassoRegression(alpha=1.0)\n",
    "lasso_model.fit(X_train, y_train)\n",
    "y_train_pred_lasso = lasso_model.predict(X_train)\n",
    "y_test_pred_lasso = lasso_model.predict(X_test)\n",
    "\n",
    "elastic_net_model = ElasticNetRegression(alpha=1.0, lambda_l1=0.5)\n",
    "elastic_net_model.fit(X_train, y_train)\n",
    "y_train_pred_en = elastic_net_model.predict(X_train)\n",
    "y_test_pred_en = elastic_net_model.predict(X_test)\n",
    "\n",
    "sklearn_ridge = Ridge(alpha=1.0)\n",
    "sklearn_ridge.fit(X_train, y_train)\n",
    "y_train_pred_sklearn_ridge = sklearn_ridge.predict(X_train)\n",
    "y_test_pred_sklearn_ridge = sklearn_ridge.predict(X_test)\n",
    "\n",
    "sklearn_lasso = Lasso(alpha=1.0)\n",
    "sklearn_lasso.fit(X_train, y_train)\n",
    "y_train_pred_sklearn_lasso = sklearn_lasso.predict(X_train)\n",
    "y_test_pred_sklearn_lasso = sklearn_lasso.predict(X_test)\n",
    "\n",
    "sklearn_en = ElasticNet(alpha=1.0, l1_ratio=0.5)\n",
    "sklearn_en.fit(X_train, y_train)\n",
    "y_train_pred_sklearn_en = sklearn_en.predict(X_train)\n",
    "y_test_pred_sklearn_en = sklearn_en.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train MAE</th>\n",
       "      <th>Test MAE</th>\n",
       "      <th>Train RMSE</th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>Train R2</th>\n",
       "      <th>Test R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ridge / Own</td>\n",
       "      <td>714.464092</td>\n",
       "      <td>915.241402</td>\n",
       "      <td>1042.964371</td>\n",
       "      <td>9604.315065</td>\n",
       "      <td>0.573835</td>\n",
       "      <td>0.022259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lasso / Own</td>\n",
       "      <td>714.690934</td>\n",
       "      <td>915.574754</td>\n",
       "      <td>1043.450015</td>\n",
       "      <td>9604.483551</td>\n",
       "      <td>0.573438</td>\n",
       "      <td>0.022225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ElasticNet / Own</td>\n",
       "      <td>781.214383</td>\n",
       "      <td>997.684362</td>\n",
       "      <td>1167.398242</td>\n",
       "      <td>9627.121413</td>\n",
       "      <td>0.466079</td>\n",
       "      <td>0.017610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ridge / Sk</td>\n",
       "      <td>711.787958</td>\n",
       "      <td>909.889257</td>\n",
       "      <td>1035.351581</td>\n",
       "      <td>9603.902155</td>\n",
       "      <td>0.580034</td>\n",
       "      <td>0.022343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lasso / Sk</td>\n",
       "      <td>711.397528</td>\n",
       "      <td>909.673381</td>\n",
       "      <td>1035.548526</td>\n",
       "      <td>9604.188597</td>\n",
       "      <td>0.579874</td>\n",
       "      <td>0.022285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ElasticNet / Sk</td>\n",
       "      <td>807.091675</td>\n",
       "      <td>1025.775253</td>\n",
       "      <td>1189.929013</td>\n",
       "      <td>9631.131965</td>\n",
       "      <td>0.445271</td>\n",
       "      <td>0.016792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Model   Train MAE     Test MAE   Train RMSE    Test RMSE  \\\n",
       "0       Ridge / Own  714.464092   915.241402  1042.964371  9604.315065   \n",
       "1       Lasso / Own  714.690934   915.574754  1043.450015  9604.483551   \n",
       "2  ElasticNet / Own  781.214383   997.684362  1167.398242  9627.121413   \n",
       "3        Ridge / Sk  711.787958   909.889257  1035.351581  9603.902155   \n",
       "4        Lasso / Sk  711.397528   909.673381  1035.548526  9604.188597   \n",
       "5   ElasticNet / Sk  807.091675  1025.775253  1189.929013  9631.131965   \n",
       "\n",
       "   Train R2   Test R2  \n",
       "0  0.573835  0.022259  \n",
       "1  0.573438  0.022225  \n",
       "2  0.466079  0.017610  \n",
       "3  0.580034  0.022343  \n",
       "4  0.579874  0.022285  \n",
       "5  0.445271  0.016792  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = {\n",
    "    'Model': [],\n",
    "    'Train MAE': [],\n",
    "    'Test MAE': [],\n",
    "    'Train RMSE': [],\n",
    "    'Test RMSE': [],\n",
    "    'Train R2': [],\n",
    "    'Test R2': []\n",
    "}\n",
    "\n",
    "for name, y_train_pred, y_test_pred in [\n",
    "    ('Ridge / Own', y_train_pred_ridge, y_test_pred_ridge),\n",
    "    ('Lasso / Own', y_train_pred_lasso, y_test_pred_lasso),\n",
    "    ('ElasticNet / Own', y_train_pred_en, y_test_pred_en),\n",
    "    ('Ridge / Sk', y_train_pred_sklearn_ridge, y_test_pred_sklearn_ridge),\n",
    "    ('Lasso / Sk', y_train_pred_sklearn_lasso, y_test_pred_sklearn_lasso),\n",
    "    ('ElasticNet / Sk', y_train_pred_sklearn_en, y_test_pred_sklearn_en),\n",
    "]:\n",
    "    train_mae, train_rmse, train_r2 = evaluate_model(y_train, y_train_pred)\n",
    "    test_mae, test_rmse, test_r2 = evaluate_model(y_test, y_test_pred)\n",
    "    \n",
    "    metrics['Model'].append(name)\n",
    "    metrics['Train MAE'].append(train_mae)\n",
    "    metrics['Test MAE'].append(test_mae)\n",
    "    metrics['Train RMSE'].append(train_rmse)\n",
    "    metrics['Test RMSE'].append(test_rmse)\n",
    "    metrics['Train R2'].append(train_r2)\n",
    "    metrics['Test R2'].append(test_r2)\n",
    "\n",
    "metrics_df_1 = pd.DataFrame(metrics)\n",
    "metrics_df_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My implementation of MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scaler(X):\n",
    "    X_min = np.min(X, axis=0)\n",
    "    X_max = np.max(X, axis=0)\n",
    "    X_scaled = (X - X_min) / (X_max - X_min)\n",
    "    return X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "data_train_scaled_sklearn = scaler.fit_transform(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_scaled_own = min_max_scaler(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison = np.allclose(data_train_scaled_own, data_train_scaled_sklearn)\n",
    "comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My implementation of StandartScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_scaler(X):\n",
    "    mean = np.mean(X, axis=0)\n",
    "    std = np.std(X, axis=0)\n",
    "    X_scaled = (X - mean) / std\n",
    "    return X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_standard = StandardScaler()\n",
    "data_train_scaled_standard_sklearn = scaler_standard.fit_transform(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_scaled_standard_own = standard_scaler(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_standard = np.allclose(data_train_scaled_standard_own, data_train_scaled_standard_sklearn)\n",
    "comparison_standard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit models with normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When Normalization Is Required  \n",
    "### Methods that are sensitive to feature scale:  \n",
    "Example: K-Nearest Neighbors (KNN)  \n",
    "KNN uses distances to determine the nearest neighbors, and if one of the features has a significantly larger scale, this can skew the results.  \n",
    "### Gradient Optimization Methods:  \n",
    "Example: Logistic Regression  \n",
    "When using gradient descent, different feature scales can lead to slow convergence. Normalization helps stabilize training.  \n",
    "### Complex Algorithms:  \n",
    "Example: Support Vector Machine (SVM)  \n",
    "SVM maximizes the gap between classes, and feature scales can affect the results. Normalization makes the influence of features equal.  \n",
    "\n",
    "## When Normalization Is Not Required  \n",
    "### Decision Trees:  \n",
    "Example: Decision Tree  \n",
    "Decision trees do not rely on distances between features, so normalization does not affect their performance. They can use raw data.  \n",
    "### Rule-based methods:  \n",
    "Example: Boosting (e.g., AdaBoost)  \n",
    "These algorithms also do not require normalization, as they focus on a single classification metric rather than the distance between observations.  \n",
    "### Handling Categorical Data:  \n",
    "Example: One-hot Encoding  \n",
    "When the input data is represented as categorical features that are assigned binary values, normalization is not required, as it does not make sense for binary features.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train MAE / MM</th>\n",
       "      <th>Test MAE / MM</th>\n",
       "      <th>Train RMSE / MM</th>\n",
       "      <th>Test RMSE / MM</th>\n",
       "      <th>Train R2 / MM</th>\n",
       "      <th>Test R2 / MM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear RegressionSDG</td>\n",
       "      <td>714.428493</td>\n",
       "      <td>914.901636</td>\n",
       "      <td>1058.381252</td>\n",
       "      <td>9609.563167</td>\n",
       "      <td>0.561143</td>\n",
       "      <td>0.021191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge / Own</td>\n",
       "      <td>938.068537</td>\n",
       "      <td>1159.911311</td>\n",
       "      <td>1358.878458</td>\n",
       "      <td>9663.430724</td>\n",
       "      <td>0.276565</td>\n",
       "      <td>0.010186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso / Own</td>\n",
       "      <td>938.494882</td>\n",
       "      <td>1160.428409</td>\n",
       "      <td>1359.595828</td>\n",
       "      <td>9663.671544</td>\n",
       "      <td>0.275801</td>\n",
       "      <td>0.010137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ElasticNet / Own</td>\n",
       "      <td>1044.473702</td>\n",
       "      <td>1274.275635</td>\n",
       "      <td>1487.642522</td>\n",
       "      <td>9693.243306</td>\n",
       "      <td>0.132967</td>\n",
       "      <td>0.004069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Linear Regression / Sk</td>\n",
       "      <td>711.791166</td>\n",
       "      <td>909.889672</td>\n",
       "      <td>1035.351576</td>\n",
       "      <td>9603.903231</td>\n",
       "      <td>0.580034</td>\n",
       "      <td>0.022343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ridge / Sk</td>\n",
       "      <td>711.868658</td>\n",
       "      <td>910.173752</td>\n",
       "      <td>1035.384206</td>\n",
       "      <td>9603.632009</td>\n",
       "      <td>0.580007</td>\n",
       "      <td>0.022398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lasso / Sk</td>\n",
       "      <td>711.649590</td>\n",
       "      <td>910.537490</td>\n",
       "      <td>1035.775591</td>\n",
       "      <td>9603.639492</td>\n",
       "      <td>0.579690</td>\n",
       "      <td>0.022397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ElasticNet / Sk</td>\n",
       "      <td>1057.169792</td>\n",
       "      <td>1287.280940</td>\n",
       "      <td>1492.374749</td>\n",
       "      <td>9693.666228</td>\n",
       "      <td>0.127442</td>\n",
       "      <td>0.003982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  Train MAE / MM  Test MAE / MM  Train RMSE / MM  \\\n",
       "0    Linear RegressionSDG      714.428493     914.901636      1058.381252   \n",
       "1             Ridge / Own      938.068537    1159.911311      1358.878458   \n",
       "2             Lasso / Own      938.494882    1160.428409      1359.595828   \n",
       "3        ElasticNet / Own     1044.473702    1274.275635      1487.642522   \n",
       "4  Linear Regression / Sk      711.791166     909.889672      1035.351576   \n",
       "5              Ridge / Sk      711.868658     910.173752      1035.384206   \n",
       "6              Lasso / Sk      711.649590     910.537490      1035.775591   \n",
       "7         ElasticNet / Sk     1057.169792    1287.280940      1492.374749   \n",
       "\n",
       "   Test RMSE / MM  Train R2 / MM  Test R2 / MM  \n",
       "0     9609.563167       0.561143      0.021191  \n",
       "1     9663.430724       0.276565      0.010186  \n",
       "2     9663.671544       0.275801      0.010137  \n",
       "3     9693.243306       0.132967      0.004069  \n",
       "4     9603.903231       0.580034      0.022343  \n",
       "5     9603.632009       0.580007      0.022398  \n",
       "6     9603.639492       0.579690      0.022397  \n",
       "7     9693.666228       0.127442      0.003982  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minmax_scaler = MinMaxScaler()\n",
    "X_train_minmax = minmax_scaler.fit_transform(X_train)\n",
    "X_test_minmax = minmax_scaler.transform(X_test)\n",
    "\n",
    "models = {\n",
    "    \"Linear RegressionSDG\": LinearRegressionSGD(),\n",
    "    \"Ridge / Own\": RidgeRegression(alpha=1.0),\n",
    "    \"Lasso / Own\": LassoRegression(alpha=1.0),\n",
    "    \"ElasticNet / Own\": ElasticNetRegression(alpha=1.0, lambda_l1=0.5),\n",
    "    \"Linear Regression / Sk\": LinearRegression(),\n",
    "    \"Ridge / Sk\": Ridge(alpha=1.0),\n",
    "    \"Lasso / Sk\": Lasso(alpha=1.0),\n",
    "    \"ElasticNet / Sk\": ElasticNet(alpha=1.0, l1_ratio=0.5)\n",
    "}\n",
    "\n",
    "results_minmax = []\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train_minmax, y_train)\n",
    "    y_train_pred = model.predict(X_train_minmax)\n",
    "    y_test_pred = model.predict(X_test_minmax)\n",
    "    \n",
    "    results_minmax.append({\n",
    "        \"Model\": model_name,\n",
    "        \"Train MAE / MM\": mean_absolute_error(y_train, y_train_pred),\n",
    "        \"Test MAE / MM\": mean_absolute_error(y_test, y_test_pred),\n",
    "        \"Train RMSE / MM\": np.sqrt(mean_squared_error(y_train, y_train_pred)),\n",
    "        \"Test RMSE / MM\": np.sqrt(mean_squared_error(y_test, y_test_pred)),\n",
    "        \"Train R2 / MM\": r2_score(y_train, y_train_pred),\n",
    "        \"Test R2 / MM\": r2_score(y_test, y_test_pred)\n",
    "    })\n",
    "\n",
    "results_minmax_df = pd.DataFrame(results_minmax)\n",
    "results_minmax_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train MAE / SS</th>\n",
       "      <th>Test MAE / SS</th>\n",
       "      <th>Train RMSE / SS</th>\n",
       "      <th>Test RMSE / SS</th>\n",
       "      <th>Train R2 / SS</th>\n",
       "      <th>Test R2 / SS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear RegressionSDG</td>\n",
       "      <td>783.481278</td>\n",
       "      <td>979.544714</td>\n",
       "      <td>1109.470293</td>\n",
       "      <td>9609.350958</td>\n",
       "      <td>0.517753</td>\n",
       "      <td>0.021234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge / Own</td>\n",
       "      <td>711.789367</td>\n",
       "      <td>909.907635</td>\n",
       "      <td>1035.411305</td>\n",
       "      <td>9603.943269</td>\n",
       "      <td>0.579985</td>\n",
       "      <td>0.022335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso / Own</td>\n",
       "      <td>711.598849</td>\n",
       "      <td>909.789976</td>\n",
       "      <td>1035.440540</td>\n",
       "      <td>9604.046446</td>\n",
       "      <td>0.579962</td>\n",
       "      <td>0.022314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ElasticNet / Own</td>\n",
       "      <td>741.715205</td>\n",
       "      <td>950.353052</td>\n",
       "      <td>1080.580304</td>\n",
       "      <td>9611.448062</td>\n",
       "      <td>0.542541</td>\n",
       "      <td>0.020807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Linear Regression / Sk</td>\n",
       "      <td>711.791166</td>\n",
       "      <td>909.889672</td>\n",
       "      <td>1035.351576</td>\n",
       "      <td>9603.903231</td>\n",
       "      <td>0.580034</td>\n",
       "      <td>0.022343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ridge / Sk</td>\n",
       "      <td>711.790594</td>\n",
       "      <td>909.889695</td>\n",
       "      <td>1035.351576</td>\n",
       "      <td>9603.903249</td>\n",
       "      <td>0.580034</td>\n",
       "      <td>0.022343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lasso / Sk</td>\n",
       "      <td>711.607870</td>\n",
       "      <td>909.784682</td>\n",
       "      <td>1035.380712</td>\n",
       "      <td>9604.018035</td>\n",
       "      <td>0.580010</td>\n",
       "      <td>0.022320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ElasticNet / Sk</td>\n",
       "      <td>741.748433</td>\n",
       "      <td>950.385313</td>\n",
       "      <td>1080.579281</td>\n",
       "      <td>9611.444892</td>\n",
       "      <td>0.542541</td>\n",
       "      <td>0.020807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  Train MAE / SS  Test MAE / SS  Train RMSE / SS  \\\n",
       "0    Linear RegressionSDG      783.481278     979.544714      1109.470293   \n",
       "1             Ridge / Own      711.789367     909.907635      1035.411305   \n",
       "2             Lasso / Own      711.598849     909.789976      1035.440540   \n",
       "3        ElasticNet / Own      741.715205     950.353052      1080.580304   \n",
       "4  Linear Regression / Sk      711.791166     909.889672      1035.351576   \n",
       "5              Ridge / Sk      711.790594     909.889695      1035.351576   \n",
       "6              Lasso / Sk      711.607870     909.784682      1035.380712   \n",
       "7         ElasticNet / Sk      741.748433     950.385313      1080.579281   \n",
       "\n",
       "   Test RMSE / SS  Train R2 / SS  Test R2 / SS  \n",
       "0     9609.350958       0.517753      0.021234  \n",
       "1     9603.943269       0.579985      0.022335  \n",
       "2     9604.046446       0.579962      0.022314  \n",
       "3     9611.448062       0.542541      0.020807  \n",
       "4     9603.903231       0.580034      0.022343  \n",
       "5     9603.903249       0.580034      0.022343  \n",
       "6     9604.018035       0.580010      0.022320  \n",
       "7     9611.444892       0.542541      0.020807  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_scaler = StandardScaler()\n",
    "X_train_standard = standard_scaler.fit_transform(X_train)\n",
    "X_test_standard = standard_scaler.transform(X_test)\n",
    "\n",
    "results_standard = []\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train_standard, y_train)\n",
    "    y_train_pred = model.predict(X_train_standard)\n",
    "    y_test_pred = model.predict(X_test_standard)\n",
    "    \n",
    "    results_standard.append({\n",
    "        \"Model\": model_name,\n",
    "        \"Train MAE / SS\": mean_absolute_error(y_train, y_train_pred),\n",
    "        \"Test MAE / SS\": mean_absolute_error(y_test, y_test_pred),\n",
    "        \"Train RMSE / SS\": np.sqrt(mean_squared_error(y_train, y_train_pred)),\n",
    "        \"Test RMSE / SS\": np.sqrt(mean_squared_error(y_test, y_test_pred)),\n",
    "        \"Train R2 / SS\": r2_score(y_train, y_train_pred),\n",
    "        \"Test R2 / SS\": r2_score(y_test, y_test_pred)\n",
    "    })\n",
    "\n",
    "results_standard_df = pd.DataFrame(results_standard)\n",
    "results_standard_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overfit models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_poly = X_train[['bathrooms', 'bedrooms']]\n",
    "X_test_poly = X_test[['bathrooms', 'bedrooms']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=10)\n",
    "X_train_poly = poly.fit_transform(X_train_poly)\n",
    "X_test_poly = poly.transform(X_test_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.877e+10, tolerance: 1.235e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.955e+10, tolerance: 1.235e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.877e+10, tolerance: 1.235e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.955e+10, tolerance: 1.235e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.877e+10, tolerance: 1.235e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.955e+10, tolerance: 1.235e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.877e+10, tolerance: 1.235e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.955e+10, tolerance: 1.235e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.877e+10, tolerance: 1.235e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.955e+10, tolerance: 1.235e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train MAE / Poly</th>\n",
       "      <th>Test MAE / Poly</th>\n",
       "      <th>Train RMSE / Poly</th>\n",
       "      <th>Test RMSE / Poly</th>\n",
       "      <th>Train R2 / Poly</th>\n",
       "      <th>Test R2 / Poly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression / Sk (alpha=0.01)</td>\n",
       "      <td>756.040301</td>\n",
       "      <td>1.448891e+16</td>\n",
       "      <td>1077.566356</td>\n",
       "      <td>3.958921e+18</td>\n",
       "      <td>0.545089</td>\n",
       "      <td>-1.661286e+29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge / Sk (alpha=0.01)</td>\n",
       "      <td>756.489063</td>\n",
       "      <td>4.559712e+15</td>\n",
       "      <td>1078.255103</td>\n",
       "      <td>1.245887e+18</td>\n",
       "      <td>0.544507</td>\n",
       "      <td>-1.645311e+28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso / Sk (alpha=0.01)</td>\n",
       "      <td>761.797661</td>\n",
       "      <td>1.165068e+10</td>\n",
       "      <td>1087.884116</td>\n",
       "      <td>3.183408e+12</td>\n",
       "      <td>0.536336</td>\n",
       "      <td>-1.074176e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ElasticNet / Sk (alpha=0.01)</td>\n",
       "      <td>767.969117</td>\n",
       "      <td>1.607383e+10</td>\n",
       "      <td>1094.692635</td>\n",
       "      <td>4.391981e+12</td>\n",
       "      <td>0.530514</td>\n",
       "      <td>-2.044616e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Linear Regression / Sk (alpha=0.1)</td>\n",
       "      <td>756.040301</td>\n",
       "      <td>1.448891e+16</td>\n",
       "      <td>1077.566356</td>\n",
       "      <td>3.958921e+18</td>\n",
       "      <td>0.545089</td>\n",
       "      <td>-1.661286e+29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ridge / Sk (alpha=0.1)</td>\n",
       "      <td>756.489063</td>\n",
       "      <td>4.559712e+15</td>\n",
       "      <td>1078.255103</td>\n",
       "      <td>1.245887e+18</td>\n",
       "      <td>0.544507</td>\n",
       "      <td>-1.645311e+28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lasso / Sk (alpha=0.1)</td>\n",
       "      <td>761.797661</td>\n",
       "      <td>1.165068e+10</td>\n",
       "      <td>1087.884116</td>\n",
       "      <td>3.183408e+12</td>\n",
       "      <td>0.536336</td>\n",
       "      <td>-1.074176e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ElasticNet / Sk (alpha=0.1)</td>\n",
       "      <td>767.969117</td>\n",
       "      <td>1.607383e+10</td>\n",
       "      <td>1094.692635</td>\n",
       "      <td>4.391981e+12</td>\n",
       "      <td>0.530514</td>\n",
       "      <td>-2.044616e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Linear Regression / Sk (alpha=1)</td>\n",
       "      <td>756.040301</td>\n",
       "      <td>1.448891e+16</td>\n",
       "      <td>1077.566356</td>\n",
       "      <td>3.958921e+18</td>\n",
       "      <td>0.545089</td>\n",
       "      <td>-1.661286e+29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ridge / Sk (alpha=1)</td>\n",
       "      <td>756.489063</td>\n",
       "      <td>4.559712e+15</td>\n",
       "      <td>1078.255103</td>\n",
       "      <td>1.245887e+18</td>\n",
       "      <td>0.544507</td>\n",
       "      <td>-1.645311e+28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Lasso / Sk (alpha=1)</td>\n",
       "      <td>761.797661</td>\n",
       "      <td>1.165068e+10</td>\n",
       "      <td>1087.884116</td>\n",
       "      <td>3.183408e+12</td>\n",
       "      <td>0.536336</td>\n",
       "      <td>-1.074176e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ElasticNet / Sk (alpha=1)</td>\n",
       "      <td>767.969117</td>\n",
       "      <td>1.607383e+10</td>\n",
       "      <td>1094.692635</td>\n",
       "      <td>4.391981e+12</td>\n",
       "      <td>0.530514</td>\n",
       "      <td>-2.044616e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Linear Regression / Sk (alpha=10)</td>\n",
       "      <td>756.040301</td>\n",
       "      <td>1.448891e+16</td>\n",
       "      <td>1077.566356</td>\n",
       "      <td>3.958921e+18</td>\n",
       "      <td>0.545089</td>\n",
       "      <td>-1.661286e+29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Ridge / Sk (alpha=10)</td>\n",
       "      <td>756.489063</td>\n",
       "      <td>4.559712e+15</td>\n",
       "      <td>1078.255103</td>\n",
       "      <td>1.245887e+18</td>\n",
       "      <td>0.544507</td>\n",
       "      <td>-1.645311e+28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Lasso / Sk (alpha=10)</td>\n",
       "      <td>761.797661</td>\n",
       "      <td>1.165068e+10</td>\n",
       "      <td>1087.884116</td>\n",
       "      <td>3.183408e+12</td>\n",
       "      <td>0.536336</td>\n",
       "      <td>-1.074176e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ElasticNet / Sk (alpha=10)</td>\n",
       "      <td>767.969117</td>\n",
       "      <td>1.607383e+10</td>\n",
       "      <td>1094.692635</td>\n",
       "      <td>4.391981e+12</td>\n",
       "      <td>0.530514</td>\n",
       "      <td>-2.044616e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Linear Regression / Sk (alpha=100)</td>\n",
       "      <td>756.040301</td>\n",
       "      <td>1.448891e+16</td>\n",
       "      <td>1077.566356</td>\n",
       "      <td>3.958921e+18</td>\n",
       "      <td>0.545089</td>\n",
       "      <td>-1.661286e+29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Ridge / Sk (alpha=100)</td>\n",
       "      <td>756.489063</td>\n",
       "      <td>4.559712e+15</td>\n",
       "      <td>1078.255103</td>\n",
       "      <td>1.245887e+18</td>\n",
       "      <td>0.544507</td>\n",
       "      <td>-1.645311e+28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Lasso / Sk (alpha=100)</td>\n",
       "      <td>761.797661</td>\n",
       "      <td>1.165068e+10</td>\n",
       "      <td>1087.884116</td>\n",
       "      <td>3.183408e+12</td>\n",
       "      <td>0.536336</td>\n",
       "      <td>-1.074176e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ElasticNet / Sk (alpha=100)</td>\n",
       "      <td>767.969117</td>\n",
       "      <td>1.607383e+10</td>\n",
       "      <td>1094.692635</td>\n",
       "      <td>4.391981e+12</td>\n",
       "      <td>0.530514</td>\n",
       "      <td>-2.044616e+17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Model  Train MAE / Poly  Test MAE / Poly  \\\n",
       "0   Linear Regression / Sk (alpha=0.01)        756.040301     1.448891e+16   \n",
       "1               Ridge / Sk (alpha=0.01)        756.489063     4.559712e+15   \n",
       "2               Lasso / Sk (alpha=0.01)        761.797661     1.165068e+10   \n",
       "3          ElasticNet / Sk (alpha=0.01)        767.969117     1.607383e+10   \n",
       "4    Linear Regression / Sk (alpha=0.1)        756.040301     1.448891e+16   \n",
       "5                Ridge / Sk (alpha=0.1)        756.489063     4.559712e+15   \n",
       "6                Lasso / Sk (alpha=0.1)        761.797661     1.165068e+10   \n",
       "7           ElasticNet / Sk (alpha=0.1)        767.969117     1.607383e+10   \n",
       "8      Linear Regression / Sk (alpha=1)        756.040301     1.448891e+16   \n",
       "9                  Ridge / Sk (alpha=1)        756.489063     4.559712e+15   \n",
       "10                 Lasso / Sk (alpha=1)        761.797661     1.165068e+10   \n",
       "11            ElasticNet / Sk (alpha=1)        767.969117     1.607383e+10   \n",
       "12    Linear Regression / Sk (alpha=10)        756.040301     1.448891e+16   \n",
       "13                Ridge / Sk (alpha=10)        756.489063     4.559712e+15   \n",
       "14                Lasso / Sk (alpha=10)        761.797661     1.165068e+10   \n",
       "15           ElasticNet / Sk (alpha=10)        767.969117     1.607383e+10   \n",
       "16   Linear Regression / Sk (alpha=100)        756.040301     1.448891e+16   \n",
       "17               Ridge / Sk (alpha=100)        756.489063     4.559712e+15   \n",
       "18               Lasso / Sk (alpha=100)        761.797661     1.165068e+10   \n",
       "19          ElasticNet / Sk (alpha=100)        767.969117     1.607383e+10   \n",
       "\n",
       "    Train RMSE / Poly  Test RMSE / Poly  Train R2 / Poly  Test R2 / Poly  \n",
       "0         1077.566356      3.958921e+18         0.545089   -1.661286e+29  \n",
       "1         1078.255103      1.245887e+18         0.544507   -1.645311e+28  \n",
       "2         1087.884116      3.183408e+12         0.536336   -1.074176e+17  \n",
       "3         1094.692635      4.391981e+12         0.530514   -2.044616e+17  \n",
       "4         1077.566356      3.958921e+18         0.545089   -1.661286e+29  \n",
       "5         1078.255103      1.245887e+18         0.544507   -1.645311e+28  \n",
       "6         1087.884116      3.183408e+12         0.536336   -1.074176e+17  \n",
       "7         1094.692635      4.391981e+12         0.530514   -2.044616e+17  \n",
       "8         1077.566356      3.958921e+18         0.545089   -1.661286e+29  \n",
       "9         1078.255103      1.245887e+18         0.544507   -1.645311e+28  \n",
       "10        1087.884116      3.183408e+12         0.536336   -1.074176e+17  \n",
       "11        1094.692635      4.391981e+12         0.530514   -2.044616e+17  \n",
       "12        1077.566356      3.958921e+18         0.545089   -1.661286e+29  \n",
       "13        1078.255103      1.245887e+18         0.544507   -1.645311e+28  \n",
       "14        1087.884116      3.183408e+12         0.536336   -1.074176e+17  \n",
       "15        1094.692635      4.391981e+12         0.530514   -2.044616e+17  \n",
       "16        1077.566356      3.958921e+18         0.545089   -1.661286e+29  \n",
       "17        1078.255103      1.245887e+18         0.544507   -1.645311e+28  \n",
       "18        1087.884116      3.183408e+12         0.536336   -1.074176e+17  \n",
       "19        1094.692635      4.391981e+12         0.530514   -2.044616e+17  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_values = [0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "models = {\n",
    "    \"Linear Regression / Sk\": LinearRegression(),\n",
    "    \"Ridge / Sk\": Ridge(),\n",
    "    \"Lasso / Sk\": Lasso(),\n",
    "    \"ElasticNet / Sk\": ElasticNet()\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for alpha in alpha_values:\n",
    "    for model_name, model in models.items():\n",
    "        if model_name in ['Ridge', 'Lasso', 'ElasticNet']:\n",
    "            model.set_params(alpha=alpha)\n",
    "\n",
    "        model.fit(X_train_poly, y_train)\n",
    "        y_train_pred = model.predict(X_train_poly)\n",
    "        y_test_pred = model.predict(X_test_poly)\n",
    "        \n",
    "        results.append({\n",
    "            \"Model\": f\"{model_name} (alpha={alpha})\",\n",
    "            \"Train MAE / Poly\": mean_absolute_error(y_train, y_train_pred),\n",
    "            \"Test MAE / Poly\": mean_absolute_error(y_test, y_test_pred),\n",
    "            \"Train RMSE / Poly\": np.sqrt(mean_squared_error(y_train, y_train_pred)),\n",
    "            \"Test RMSE / Poly\": np.sqrt(mean_squared_error(y_test, y_test_pred)),\n",
    "            \"Train R2 / Poly\": r2_score(y_train, y_train_pred),\n",
    "            \"Test R2 / Poly\": r2_score(y_test, y_test_pred)\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Native Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = metrics_df\n",
    "for df in [metrics_df_1, results_minmax_df, results_standard_df, results_df]:\n",
    "    result = pd.merge(result, df, on='Model', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_metrics = result.mean(numeric_only=True)\n",
    "median_metrics = result.median(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_df = pd.DataFrame(mean_metrics).T\n",
    "mean_df.insert(0, 'Model', 'Mean')\n",
    "\n",
    "result = pd.concat([result, mean_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_df = pd.DataFrame(median_metrics).T\n",
    "median_df.insert(0, 'Model', 'Median')\n",
    "\n",
    "result = pd.concat([result, median_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train MAE_x</th>\n",
       "      <th>Test MAE_x</th>\n",
       "      <th>Train RMSE_x</th>\n",
       "      <th>Test RMSE_x</th>\n",
       "      <th>Train R2_x</th>\n",
       "      <th>Test R2_x</th>\n",
       "      <th>Train MAE_y</th>\n",
       "      <th>Test MAE_y</th>\n",
       "      <th>Train RMSE_y</th>\n",
       "      <th>...</th>\n",
       "      <th>Train RMSE / SS</th>\n",
       "      <th>Test RMSE / SS</th>\n",
       "      <th>Train R2 / SS</th>\n",
       "      <th>Test R2 / SS</th>\n",
       "      <th>Train MAE / Poly</th>\n",
       "      <th>Test MAE / Poly</th>\n",
       "      <th>Train RMSE / Poly</th>\n",
       "      <th>Test RMSE / Poly</th>\n",
       "      <th>Train R2 / Poly</th>\n",
       "      <th>Test R2 / Poly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ElasticNet / Own</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>781.214383</td>\n",
       "      <td>997.684362</td>\n",
       "      <td>1167.398242</td>\n",
       "      <td>...</td>\n",
       "      <td>1080.580304</td>\n",
       "      <td>9611.448062</td>\n",
       "      <td>0.542541</td>\n",
       "      <td>0.020807</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ElasticNet / Sk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>807.091675</td>\n",
       "      <td>1025.775253</td>\n",
       "      <td>1189.929013</td>\n",
       "      <td>...</td>\n",
       "      <td>1080.579281</td>\n",
       "      <td>9611.444892</td>\n",
       "      <td>0.542541</td>\n",
       "      <td>0.020807</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ElasticNet / Sk (alpha=0.01)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>767.969117</td>\n",
       "      <td>1.607383e+10</td>\n",
       "      <td>1094.692635</td>\n",
       "      <td>4.391981e+12</td>\n",
       "      <td>0.530514</td>\n",
       "      <td>-2.044616e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ElasticNet / Sk (alpha=0.1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>767.969117</td>\n",
       "      <td>1.607383e+10</td>\n",
       "      <td>1094.692635</td>\n",
       "      <td>4.391981e+12</td>\n",
       "      <td>0.530514</td>\n",
       "      <td>-2.044616e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ElasticNet / Sk (alpha=1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>767.969117</td>\n",
       "      <td>1.607383e+10</td>\n",
       "      <td>1094.692635</td>\n",
       "      <td>4.391981e+12</td>\n",
       "      <td>0.530514</td>\n",
       "      <td>-2.044616e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ElasticNet / Sk (alpha=10)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>767.969117</td>\n",
       "      <td>1.607383e+10</td>\n",
       "      <td>1094.692635</td>\n",
       "      <td>4.391981e+12</td>\n",
       "      <td>0.530514</td>\n",
       "      <td>-2.044616e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ElasticNet / Sk (alpha=100)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>767.969117</td>\n",
       "      <td>1.607383e+10</td>\n",
       "      <td>1094.692635</td>\n",
       "      <td>4.391981e+12</td>\n",
       "      <td>0.530514</td>\n",
       "      <td>-2.044616e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lasso / Own</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>714.690934</td>\n",
       "      <td>915.574754</td>\n",
       "      <td>1043.450015</td>\n",
       "      <td>...</td>\n",
       "      <td>1035.440540</td>\n",
       "      <td>9604.046446</td>\n",
       "      <td>0.579962</td>\n",
       "      <td>0.022314</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lasso / Sk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>711.397528</td>\n",
       "      <td>909.673381</td>\n",
       "      <td>1035.548526</td>\n",
       "      <td>...</td>\n",
       "      <td>1035.380712</td>\n",
       "      <td>9604.018035</td>\n",
       "      <td>0.580010</td>\n",
       "      <td>0.022320</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lasso / Sk (alpha=0.01)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>761.797661</td>\n",
       "      <td>1.165068e+10</td>\n",
       "      <td>1087.884116</td>\n",
       "      <td>3.183408e+12</td>\n",
       "      <td>0.536336</td>\n",
       "      <td>-1.074176e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Lasso / Sk (alpha=0.1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>761.797661</td>\n",
       "      <td>1.165068e+10</td>\n",
       "      <td>1087.884116</td>\n",
       "      <td>3.183408e+12</td>\n",
       "      <td>0.536336</td>\n",
       "      <td>-1.074176e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Lasso / Sk (alpha=1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>761.797661</td>\n",
       "      <td>1.165068e+10</td>\n",
       "      <td>1087.884116</td>\n",
       "      <td>3.183408e+12</td>\n",
       "      <td>0.536336</td>\n",
       "      <td>-1.074176e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Lasso / Sk (alpha=10)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>761.797661</td>\n",
       "      <td>1.165068e+10</td>\n",
       "      <td>1087.884116</td>\n",
       "      <td>3.183408e+12</td>\n",
       "      <td>0.536336</td>\n",
       "      <td>-1.074176e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Lasso / Sk (alpha=100)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>761.797661</td>\n",
       "      <td>1.165068e+10</td>\n",
       "      <td>1087.884116</td>\n",
       "      <td>3.183408e+12</td>\n",
       "      <td>0.536336</td>\n",
       "      <td>-1.074176e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Linear Regression / Sk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1035.351576</td>\n",
       "      <td>9603.903231</td>\n",
       "      <td>0.580034</td>\n",
       "      <td>0.022343</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Linear Regression / Sk (alpha=0.01)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>756.040301</td>\n",
       "      <td>1.448891e+16</td>\n",
       "      <td>1077.566356</td>\n",
       "      <td>3.958921e+18</td>\n",
       "      <td>0.545089</td>\n",
       "      <td>-1.661286e+29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Linear Regression / Sk (alpha=0.1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>756.040301</td>\n",
       "      <td>1.448891e+16</td>\n",
       "      <td>1077.566356</td>\n",
       "      <td>3.958921e+18</td>\n",
       "      <td>0.545089</td>\n",
       "      <td>-1.661286e+29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Linear Regression / Sk (alpha=1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>756.040301</td>\n",
       "      <td>1.448891e+16</td>\n",
       "      <td>1077.566356</td>\n",
       "      <td>3.958921e+18</td>\n",
       "      <td>0.545089</td>\n",
       "      <td>-1.661286e+29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Linear Regression / Sk (alpha=10)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>756.040301</td>\n",
       "      <td>1.448891e+16</td>\n",
       "      <td>1077.566356</td>\n",
       "      <td>3.958921e+18</td>\n",
       "      <td>0.545089</td>\n",
       "      <td>-1.661286e+29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Linear Regression / Sk (alpha=100)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>756.040301</td>\n",
       "      <td>1.448891e+16</td>\n",
       "      <td>1077.566356</td>\n",
       "      <td>3.958921e+18</td>\n",
       "      <td>0.545089</td>\n",
       "      <td>-1.661286e+29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Linear RegressionSDG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1109.470293</td>\n",
       "      <td>9609.350958</td>\n",
       "      <td>0.517753</td>\n",
       "      <td>0.021234</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LinearRegression / Sk</td>\n",
       "      <td>711.791166</td>\n",
       "      <td>909.889672</td>\n",
       "      <td>1035.351576</td>\n",
       "      <td>9603.903231</td>\n",
       "      <td>0.580034</td>\n",
       "      <td>0.022343</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>LinearRegressionAnalytic</td>\n",
       "      <td>711.791166</td>\n",
       "      <td>909.889672</td>\n",
       "      <td>1035.351576</td>\n",
       "      <td>9603.903231</td>\n",
       "      <td>0.580034</td>\n",
       "      <td>0.022343</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>LinearRegressionSGD</td>\n",
       "      <td>718.081663</td>\n",
       "      <td>920.993858</td>\n",
       "      <td>1071.763291</td>\n",
       "      <td>9609.922737</td>\n",
       "      <td>0.549975</td>\n",
       "      <td>0.021117</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Ridge / Own</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>714.464092</td>\n",
       "      <td>915.241402</td>\n",
       "      <td>1042.964371</td>\n",
       "      <td>...</td>\n",
       "      <td>1035.411305</td>\n",
       "      <td>9603.943269</td>\n",
       "      <td>0.579985</td>\n",
       "      <td>0.022335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Ridge / Sk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>711.787958</td>\n",
       "      <td>909.889257</td>\n",
       "      <td>1035.351581</td>\n",
       "      <td>...</td>\n",
       "      <td>1035.351576</td>\n",
       "      <td>9603.903249</td>\n",
       "      <td>0.580034</td>\n",
       "      <td>0.022343</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Ridge / Sk (alpha=0.01)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>756.489063</td>\n",
       "      <td>4.559712e+15</td>\n",
       "      <td>1078.255103</td>\n",
       "      <td>1.245887e+18</td>\n",
       "      <td>0.544507</td>\n",
       "      <td>-1.645311e+28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Ridge / Sk (alpha=0.1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>756.489063</td>\n",
       "      <td>4.559712e+15</td>\n",
       "      <td>1078.255103</td>\n",
       "      <td>1.245887e+18</td>\n",
       "      <td>0.544507</td>\n",
       "      <td>-1.645311e+28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Ridge / Sk (alpha=1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>756.489063</td>\n",
       "      <td>4.559712e+15</td>\n",
       "      <td>1078.255103</td>\n",
       "      <td>1.245887e+18</td>\n",
       "      <td>0.544507</td>\n",
       "      <td>-1.645311e+28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Ridge / Sk (alpha=10)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>756.489063</td>\n",
       "      <td>4.559712e+15</td>\n",
       "      <td>1078.255103</td>\n",
       "      <td>1.245887e+18</td>\n",
       "      <td>0.544507</td>\n",
       "      <td>-1.645311e+28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Ridge / Sk (alpha=100)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>756.489063</td>\n",
       "      <td>4.559712e+15</td>\n",
       "      <td>1078.255103</td>\n",
       "      <td>1.245887e+18</td>\n",
       "      <td>0.544507</td>\n",
       "      <td>-1.645311e+28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Mean</td>\n",
       "      <td>713.887998</td>\n",
       "      <td>913.591068</td>\n",
       "      <td>1047.488814</td>\n",
       "      <td>9605.909733</td>\n",
       "      <td>0.570014</td>\n",
       "      <td>0.021935</td>\n",
       "      <td>740.107762</td>\n",
       "      <td>945.639735</td>\n",
       "      <td>1085.773625</td>\n",
       "      <td>...</td>\n",
       "      <td>1055.945698</td>\n",
       "      <td>9606.507268</td>\n",
       "      <td>0.562857</td>\n",
       "      <td>0.021813</td>\n",
       "      <td>760.574035</td>\n",
       "      <td>4.762163e+15</td>\n",
       "      <td>1084.599552</td>\n",
       "      <td>1.301204e+18</td>\n",
       "      <td>0.539111</td>\n",
       "      <td>-4.564543e+28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Median</td>\n",
       "      <td>711.791166</td>\n",
       "      <td>909.889672</td>\n",
       "      <td>1035.351576</td>\n",
       "      <td>9603.903231</td>\n",
       "      <td>0.580034</td>\n",
       "      <td>0.022343</td>\n",
       "      <td>714.577513</td>\n",
       "      <td>915.408078</td>\n",
       "      <td>1043.207193</td>\n",
       "      <td>...</td>\n",
       "      <td>1035.425923</td>\n",
       "      <td>9604.032240</td>\n",
       "      <td>0.579974</td>\n",
       "      <td>0.022317</td>\n",
       "      <td>759.143362</td>\n",
       "      <td>2.279864e+15</td>\n",
       "      <td>1083.069609</td>\n",
       "      <td>6.229455e+17</td>\n",
       "      <td>0.540421</td>\n",
       "      <td>-8.226553e+27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Model  Train MAE_x  Test MAE_x  \\\n",
       "0                      ElasticNet / Own          NaN         NaN   \n",
       "1                       ElasticNet / Sk          NaN         NaN   \n",
       "2          ElasticNet / Sk (alpha=0.01)          NaN         NaN   \n",
       "3           ElasticNet / Sk (alpha=0.1)          NaN         NaN   \n",
       "4             ElasticNet / Sk (alpha=1)          NaN         NaN   \n",
       "5            ElasticNet / Sk (alpha=10)          NaN         NaN   \n",
       "6           ElasticNet / Sk (alpha=100)          NaN         NaN   \n",
       "7                           Lasso / Own          NaN         NaN   \n",
       "8                            Lasso / Sk          NaN         NaN   \n",
       "9               Lasso / Sk (alpha=0.01)          NaN         NaN   \n",
       "10               Lasso / Sk (alpha=0.1)          NaN         NaN   \n",
       "11                 Lasso / Sk (alpha=1)          NaN         NaN   \n",
       "12                Lasso / Sk (alpha=10)          NaN         NaN   \n",
       "13               Lasso / Sk (alpha=100)          NaN         NaN   \n",
       "14               Linear Regression / Sk          NaN         NaN   \n",
       "15  Linear Regression / Sk (alpha=0.01)          NaN         NaN   \n",
       "16   Linear Regression / Sk (alpha=0.1)          NaN         NaN   \n",
       "17     Linear Regression / Sk (alpha=1)          NaN         NaN   \n",
       "18    Linear Regression / Sk (alpha=10)          NaN         NaN   \n",
       "19   Linear Regression / Sk (alpha=100)          NaN         NaN   \n",
       "20                 Linear RegressionSDG          NaN         NaN   \n",
       "21                LinearRegression / Sk   711.791166  909.889672   \n",
       "22             LinearRegressionAnalytic   711.791166  909.889672   \n",
       "23                  LinearRegressionSGD   718.081663  920.993858   \n",
       "24                          Ridge / Own          NaN         NaN   \n",
       "25                           Ridge / Sk          NaN         NaN   \n",
       "26              Ridge / Sk (alpha=0.01)          NaN         NaN   \n",
       "27               Ridge / Sk (alpha=0.1)          NaN         NaN   \n",
       "28                 Ridge / Sk (alpha=1)          NaN         NaN   \n",
       "29                Ridge / Sk (alpha=10)          NaN         NaN   \n",
       "30               Ridge / Sk (alpha=100)          NaN         NaN   \n",
       "31                                 Mean   713.887998  913.591068   \n",
       "32                               Median   711.791166  909.889672   \n",
       "\n",
       "    Train RMSE_x  Test RMSE_x  Train R2_x  Test R2_x  Train MAE_y  \\\n",
       "0            NaN          NaN         NaN        NaN   781.214383   \n",
       "1            NaN          NaN         NaN        NaN   807.091675   \n",
       "2            NaN          NaN         NaN        NaN          NaN   \n",
       "3            NaN          NaN         NaN        NaN          NaN   \n",
       "4            NaN          NaN         NaN        NaN          NaN   \n",
       "5            NaN          NaN         NaN        NaN          NaN   \n",
       "6            NaN          NaN         NaN        NaN          NaN   \n",
       "7            NaN          NaN         NaN        NaN   714.690934   \n",
       "8            NaN          NaN         NaN        NaN   711.397528   \n",
       "9            NaN          NaN         NaN        NaN          NaN   \n",
       "10           NaN          NaN         NaN        NaN          NaN   \n",
       "11           NaN          NaN         NaN        NaN          NaN   \n",
       "12           NaN          NaN         NaN        NaN          NaN   \n",
       "13           NaN          NaN         NaN        NaN          NaN   \n",
       "14           NaN          NaN         NaN        NaN          NaN   \n",
       "15           NaN          NaN         NaN        NaN          NaN   \n",
       "16           NaN          NaN         NaN        NaN          NaN   \n",
       "17           NaN          NaN         NaN        NaN          NaN   \n",
       "18           NaN          NaN         NaN        NaN          NaN   \n",
       "19           NaN          NaN         NaN        NaN          NaN   \n",
       "20           NaN          NaN         NaN        NaN          NaN   \n",
       "21   1035.351576  9603.903231    0.580034   0.022343          NaN   \n",
       "22   1035.351576  9603.903231    0.580034   0.022343          NaN   \n",
       "23   1071.763291  9609.922737    0.549975   0.021117          NaN   \n",
       "24           NaN          NaN         NaN        NaN   714.464092   \n",
       "25           NaN          NaN         NaN        NaN   711.787958   \n",
       "26           NaN          NaN         NaN        NaN          NaN   \n",
       "27           NaN          NaN         NaN        NaN          NaN   \n",
       "28           NaN          NaN         NaN        NaN          NaN   \n",
       "29           NaN          NaN         NaN        NaN          NaN   \n",
       "30           NaN          NaN         NaN        NaN          NaN   \n",
       "31   1047.488814  9605.909733    0.570014   0.021935   740.107762   \n",
       "32   1035.351576  9603.903231    0.580034   0.022343   714.577513   \n",
       "\n",
       "     Test MAE_y  Train RMSE_y  ...  Train RMSE / SS  Test RMSE / SS  \\\n",
       "0    997.684362   1167.398242  ...      1080.580304     9611.448062   \n",
       "1   1025.775253   1189.929013  ...      1080.579281     9611.444892   \n",
       "2           NaN           NaN  ...              NaN             NaN   \n",
       "3           NaN           NaN  ...              NaN             NaN   \n",
       "4           NaN           NaN  ...              NaN             NaN   \n",
       "5           NaN           NaN  ...              NaN             NaN   \n",
       "6           NaN           NaN  ...              NaN             NaN   \n",
       "7    915.574754   1043.450015  ...      1035.440540     9604.046446   \n",
       "8    909.673381   1035.548526  ...      1035.380712     9604.018035   \n",
       "9           NaN           NaN  ...              NaN             NaN   \n",
       "10          NaN           NaN  ...              NaN             NaN   \n",
       "11          NaN           NaN  ...              NaN             NaN   \n",
       "12          NaN           NaN  ...              NaN             NaN   \n",
       "13          NaN           NaN  ...              NaN             NaN   \n",
       "14          NaN           NaN  ...      1035.351576     9603.903231   \n",
       "15          NaN           NaN  ...              NaN             NaN   \n",
       "16          NaN           NaN  ...              NaN             NaN   \n",
       "17          NaN           NaN  ...              NaN             NaN   \n",
       "18          NaN           NaN  ...              NaN             NaN   \n",
       "19          NaN           NaN  ...              NaN             NaN   \n",
       "20          NaN           NaN  ...      1109.470293     9609.350958   \n",
       "21          NaN           NaN  ...              NaN             NaN   \n",
       "22          NaN           NaN  ...              NaN             NaN   \n",
       "23          NaN           NaN  ...              NaN             NaN   \n",
       "24   915.241402   1042.964371  ...      1035.411305     9603.943269   \n",
       "25   909.889257   1035.351581  ...      1035.351576     9603.903249   \n",
       "26          NaN           NaN  ...              NaN             NaN   \n",
       "27          NaN           NaN  ...              NaN             NaN   \n",
       "28          NaN           NaN  ...              NaN             NaN   \n",
       "29          NaN           NaN  ...              NaN             NaN   \n",
       "30          NaN           NaN  ...              NaN             NaN   \n",
       "31   945.639735   1085.773625  ...      1055.945698     9606.507268   \n",
       "32   915.408078   1043.207193  ...      1035.425923     9604.032240   \n",
       "\n",
       "    Train R2 / SS  Test R2 / SS  Train MAE / Poly  Test MAE / Poly  \\\n",
       "0        0.542541      0.020807               NaN              NaN   \n",
       "1        0.542541      0.020807               NaN              NaN   \n",
       "2             NaN           NaN        767.969117     1.607383e+10   \n",
       "3             NaN           NaN        767.969117     1.607383e+10   \n",
       "4             NaN           NaN        767.969117     1.607383e+10   \n",
       "5             NaN           NaN        767.969117     1.607383e+10   \n",
       "6             NaN           NaN        767.969117     1.607383e+10   \n",
       "7        0.579962      0.022314               NaN              NaN   \n",
       "8        0.580010      0.022320               NaN              NaN   \n",
       "9             NaN           NaN        761.797661     1.165068e+10   \n",
       "10            NaN           NaN        761.797661     1.165068e+10   \n",
       "11            NaN           NaN        761.797661     1.165068e+10   \n",
       "12            NaN           NaN        761.797661     1.165068e+10   \n",
       "13            NaN           NaN        761.797661     1.165068e+10   \n",
       "14       0.580034      0.022343               NaN              NaN   \n",
       "15            NaN           NaN        756.040301     1.448891e+16   \n",
       "16            NaN           NaN        756.040301     1.448891e+16   \n",
       "17            NaN           NaN        756.040301     1.448891e+16   \n",
       "18            NaN           NaN        756.040301     1.448891e+16   \n",
       "19            NaN           NaN        756.040301     1.448891e+16   \n",
       "20       0.517753      0.021234               NaN              NaN   \n",
       "21            NaN           NaN               NaN              NaN   \n",
       "22            NaN           NaN               NaN              NaN   \n",
       "23            NaN           NaN               NaN              NaN   \n",
       "24       0.579985      0.022335               NaN              NaN   \n",
       "25       0.580034      0.022343               NaN              NaN   \n",
       "26            NaN           NaN        756.489063     4.559712e+15   \n",
       "27            NaN           NaN        756.489063     4.559712e+15   \n",
       "28            NaN           NaN        756.489063     4.559712e+15   \n",
       "29            NaN           NaN        756.489063     4.559712e+15   \n",
       "30            NaN           NaN        756.489063     4.559712e+15   \n",
       "31       0.562857      0.021813        760.574035     4.762163e+15   \n",
       "32       0.579974      0.022317        759.143362     2.279864e+15   \n",
       "\n",
       "    Train RMSE / Poly  Test RMSE / Poly  Train R2 / Poly  Test R2 / Poly  \n",
       "0                 NaN               NaN              NaN             NaN  \n",
       "1                 NaN               NaN              NaN             NaN  \n",
       "2         1094.692635      4.391981e+12         0.530514   -2.044616e+17  \n",
       "3         1094.692635      4.391981e+12         0.530514   -2.044616e+17  \n",
       "4         1094.692635      4.391981e+12         0.530514   -2.044616e+17  \n",
       "5         1094.692635      4.391981e+12         0.530514   -2.044616e+17  \n",
       "6         1094.692635      4.391981e+12         0.530514   -2.044616e+17  \n",
       "7                 NaN               NaN              NaN             NaN  \n",
       "8                 NaN               NaN              NaN             NaN  \n",
       "9         1087.884116      3.183408e+12         0.536336   -1.074176e+17  \n",
       "10        1087.884116      3.183408e+12         0.536336   -1.074176e+17  \n",
       "11        1087.884116      3.183408e+12         0.536336   -1.074176e+17  \n",
       "12        1087.884116      3.183408e+12         0.536336   -1.074176e+17  \n",
       "13        1087.884116      3.183408e+12         0.536336   -1.074176e+17  \n",
       "14                NaN               NaN              NaN             NaN  \n",
       "15        1077.566356      3.958921e+18         0.545089   -1.661286e+29  \n",
       "16        1077.566356      3.958921e+18         0.545089   -1.661286e+29  \n",
       "17        1077.566356      3.958921e+18         0.545089   -1.661286e+29  \n",
       "18        1077.566356      3.958921e+18         0.545089   -1.661286e+29  \n",
       "19        1077.566356      3.958921e+18         0.545089   -1.661286e+29  \n",
       "20                NaN               NaN              NaN             NaN  \n",
       "21                NaN               NaN              NaN             NaN  \n",
       "22                NaN               NaN              NaN             NaN  \n",
       "23                NaN               NaN              NaN             NaN  \n",
       "24                NaN               NaN              NaN             NaN  \n",
       "25                NaN               NaN              NaN             NaN  \n",
       "26        1078.255103      1.245887e+18         0.544507   -1.645311e+28  \n",
       "27        1078.255103      1.245887e+18         0.544507   -1.645311e+28  \n",
       "28        1078.255103      1.245887e+18         0.544507   -1.645311e+28  \n",
       "29        1078.255103      1.245887e+18         0.544507   -1.645311e+28  \n",
       "30        1078.255103      1.245887e+18         0.544507   -1.645311e+28  \n",
       "31        1084.599552      1.301204e+18         0.539111   -4.564543e+28  \n",
       "32        1083.069609      6.229455e+17         0.540421   -8.226553e+27  \n",
       "\n",
       "[33 rows x 31 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The best method turned out to be <i>LassoRegression with MinMaxScaler normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Addition task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_train.drop('price', axis=1), data_train['price'], train_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_log = np.log1p(y_train)  # log(Y + 1)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train_log)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train_log)\n",
    "\n",
    "y_pred_log = model.predict(X_test)\n",
    "y_pred = np.expm1(y_pred_log)  # exp(predictions) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 2.6261573898733584e-23\n",
      "R^2: 1.0\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "\n",
    "r_2 = r2_score(y_test, y_pred)\n",
    "print(f'R^2: {r_2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "sns.scatterplot(x=y_test, y=y_pred)\n",
    "plt.title('Predictions vs Actual Values')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
